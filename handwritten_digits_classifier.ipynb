{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "# Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader without Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "non_normalized_tranform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create train set and define loader\n",
    "non_normalized_train_data = torchvision.datasets.MNIST('data', train=True, download=True, transform=non_normalized_tranform)\n",
    "nn_train_loader = torch.utils.data.DataLoader(non_normalized_train_data, batch_size=len(non_normalized_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "# For normalization use calculated values: mean, std\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307), (0.3081))])\n",
    "\n",
    "# Create train set and define train dataloader\n",
    "train_data = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "# len(train_data) - batch size\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=250, shuffle=True)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "test_data = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `transforms.ToTensor()` - converting PIL image to tensor.\n",
    "- `transforms.Normalize` - helps learn faster. Normalization can also help with the diminishing and exploding gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can plot image values by using `plot` function - it takes data loader as an argument\n",
    "\n",
    "def plot(loader):\n",
    "  data = next(iter(loader))\n",
    "  # Calculation of the Mean and Standart deviation (std)\n",
    "  print(data[0].mean(), data[0].std())\n",
    "  \n",
    "  data_list = np.array(data[0])\n",
    "  flatten_data_list = data_list.flatten()\n",
    "  \n",
    "  # plot image values\n",
    "  plt.hist(flatten_data_list)\n",
    "  \n",
    "  # plot mean value\n",
    "  plt.axvline(data[0].mean(), linestyle='--')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized data or non normalized data by calling plot function\n",
    "\n",
    "# non normalized values\n",
    "plot(nn_train_loader)\n",
    "# normalized values\n",
    "plot(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "# normalized data\n",
    "show5(train_loader)\n",
    "\n",
    "# non normlized\n",
    "show5(nn_train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.fc3 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.fc3(x)\n",
    "        \n",
    "model = Model() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "critereon = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop - Running Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_history = []\n",
    "train_val_accuracy_history = []\n",
    "\n",
    "def train_model(model, train_loader, optimizer, critereon, epochs=10):\n",
    "# Will be used for early stopping\n",
    "\tbest_val_loss = float('inf')\n",
    "\tthreshold = 0.0001\n",
    "\tcounter = 0\n",
    "\tpatience = 3\n",
    " \n",
    "\tfor epoch in range(epochs):\n",
    "\t\t# Switch to training mode\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\ttrain_loss = 0.0\n",
    "\t\ttrain_correct = 0\n",
    "\t\tfor batch in train_loader:\n",
    "\t\t\timages, labels = batch\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutput = model(images)\n",
    "\t\t\tloss = critereon(output, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t_, predicted_class = torch.max(output.data, 1)\n",
    "\t\t\ttrain_correct += (predicted_class == labels).sum().item()\n",
    "\t\t\ttrain_loss += loss.item()\n",
    "\n",
    "\t\ttrain_val_loss_history.append(train_loss / len(train_loader.dataset))\n",
    "\t\ttrain_val_accuracy_history.append(train_correct / len(train_loader.dataset))\n",
    "\t\tprint(f'Epoch: {epoch + 1}, Accuracy: {train_correct / len(train_loader.dataset):.2f}, Loss: {train_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "\t\tval_loss = 0.0\n",
    "\t\tval_correct = 0\n",
    "\n",
    "\t\t# Switch to evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\tfor inputs, labels in test_loader:\n",
    "\t\t\toutput = model(inputs)\n",
    "\t\t\tloss = critereon(output, labels)\n",
    "\t\t\tval_loss += loss.item()\n",
    "\t\t\t_, predicted = torch.max(output.data, 1)\n",
    "\t\t\tval_correct += (predicted == labels).sum().item()\n",
    "\t\tprint(f'Validation accuracy: {val_correct / len(test_loader.dataset):.2f}, Validation loss: {val_loss / len(test_loader.dataset):.4f}')\n",
    "\n",
    "\t\t# Early stopping\n",
    "\t\tif best_val_loss > val_loss:\n",
    "\t\t\tbest_val_loss = val_loss\n",
    "\n",
    "\t\tdiff = best_val_loss - val_loss\n",
    "\t\tif diff <= threshold:\n",
    "\t\t\tcounter += 1\n",
    "\n",
    "\t\tif counter >= patience:\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, optimizer, critereon, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_val_loss_history, label=\"Training Loss\")\n",
    "plt.plot(train_val_accuracy_history, label=\"Training validation accuracy\")\n",
    "plt.legend()\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the trained model\n",
    "torch.save(model.state_dict(), 'weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
